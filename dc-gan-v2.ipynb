{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa58bc8c",
   "metadata": {},
   "source": [
    "latest and working code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2464aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5189821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128\n",
    "img_size = 32\n",
    "channels = 3\n",
    "\n",
    "lr_g = 0.0002  \n",
    "lr_d = 0.0001 \n",
    "b1, b2 = 0.5, 0.999\n",
    "batch_size = 64\n",
    "num_epochs = 200\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "d_train_freq = 1 \n",
    "g_train_freq = 2  \n",
    "\n",
    "\n",
    "def list_images(basePath, contains=None):\n",
    "    return list_files(basePath, validExts=(\".jpg\", \".jpeg\", \".png\", \".bmp\"), contains=contains)\n",
    "\n",
    "def list_files(basePath, validExts=(\".jpg\", \".jpeg\", \".png\", \".bmp\"), contains=None):\n",
    "    for (rootDir, dirNames, filenames) in os.walk(basePath):\n",
    "        for filename in filenames:\n",
    "            if contains is not None and filename.find(contains) == -1:\n",
    "                continue\n",
    "            ext = filename[filename.rfind(\".\"):].lower()\n",
    "            if ext.endswith(validExts):\n",
    "                imagePath = os.path.join(rootDir, filename).replace(\" \", \"\\\\ \")\n",
    "                yield imagePath\n",
    "\n",
    "def load_images(directory='', size=(64,64)):\n",
    "    images = []\n",
    "    imagePaths = list(list_images(directory))\n",
    "    \n",
    "    for path in imagePaths:\n",
    "        if not('OSX' in path):\n",
    "            path = path.replace('\\\\','/')\n",
    "            image = cv2.imread(path)\n",
    "            if image is not None:\n",
    "                image = cv2.resize(image, size)\n",
    "                images.append(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d521348",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, directory, img_size=32, transform=None):\n",
    "        self.images = load_images(directory, size=(img_size, img_size))\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        image = Image.fromarray(image.astype('uint8'))\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e82fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def spectral_norm(module):\n",
    "    \"\"\"Apply spectral normalization to a module\"\"\"\n",
    "    return nn.utils.spectral_norm(module)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, channels):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "     \n",
    "            spectral_norm(nn.ConvTranspose2d(latent_dim, 512, 4, 1, 0)),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            spectral_norm(nn.ConvTranspose2d(512, 256, 4, 2, 1)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            spectral_norm(nn.ConvTranspose2d(256, 128, 4, 2, 1)),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            spectral_norm(nn.ConvTranspose2d(128, channels, 4, 2, 1)),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12de2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    " \n",
    "            nn.Conv2d(channels, 128, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),  \n",
    "\n",
    "            nn.Conv2d(128, 256, 4, 2, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "\n",
    "            nn.Conv2d(256, 512, 4, 2, 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "\n",
    "            nn.Conv2d(512, 1, 4, 1, 0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.model(img).view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2828fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "adversarial_loss = nn.BCELoss()\n",
    "generator = Generator(latent_dim, channels).to(device)\n",
    "discriminator = Discriminator(channels).to(device)\n",
    "\n",
    "\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr_g, betas=(b1, b2))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr_d, betas=(b1, b2))\n",
    "\n",
    "scheduler_G = optim.lr_scheduler.ExponentialLR(optimizer_G, gamma=0.99)\n",
    "scheduler_D = optim.lr_scheduler.ExponentialLR(optimizer_D, gamma=0.99)\n",
    "\n",
    "\n",
    "data_path = \"/kaggle/input/anime-faces/data\"\n",
    "\n",
    "print(\"Available datasets in /kaggle/input/:\")\n",
    "for item in os.listdir(\"/kaggle/input/\"):\n",
    "    print(f\"- {item}\")\n",
    "    item_path = f\"/kaggle/input/{item}\"\n",
    "    if os.path.isdir(item_path):\n",
    "        print(f\"  Contents: {os.listdir(item_path)}\")\n",
    "print()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.CenterCrop(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "dataset = CustomImageDataset(data_path, img_size=img_size, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "print(f\"Dataset loaded successfully! Total images: {len(dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34797932",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (real_imgs, _) in enumerate(dataloader):\n",
    "        real_imgs = real_imgs.to(device)\n",
    "        batch_size_current = real_imgs.size(0)\n",
    "        \n",
    "        # using Label smoothing over here-  soft labels instead of hard i.e. 0/1\n",
    "        real_labels = torch.ones(batch_size_current, 1).to(device) * 0.9  # 0.9 instead of 1.0\n",
    "        fake_labels = torch.zeros(batch_size_current, 1).to(device) + 0.1  # 0.1 instead of 0.0\n",
    "\n",
    "        # Generating fake images\n",
    "        z = torch.randn(batch_size_current, latent_dim, 1, 1).to(device)\n",
    "        fake_imgs = generator(z)\n",
    "\n",
    "        #Train Discriminator (less frequently , to avoid disciminator from becoming too strong) \n",
    "        if i % d_train_freq == 0:\n",
    "            optimizer_D.zero_grad()\n",
    "            \n",
    "            # Real images\n",
    "            real_pred = discriminator(real_imgs)\n",
    "            real_loss = adversarial_loss(real_pred, real_labels)\n",
    "            \n",
    "            # Fake images\n",
    "            fake_pred = discriminator(fake_imgs.detach())\n",
    "            fake_loss = adversarial_loss(fake_pred, fake_labels)\n",
    "            \n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "            \n",
    "            \n",
    "            if d_loss.item() > 0.1:  # Preventing discriminator from becoming too strong by using less frequent training\n",
    "                d_loss.backward()\n",
    "                optimizer_D.step()\n",
    "\n",
    "        \n",
    "        if i % g_train_freq == 0:\n",
    "            optimizer_G.zero_grad()\n",
    "\n",
    "            fake_pred = discriminator(fake_imgs)\n",
    "            g_loss = adversarial_loss(fake_pred, real_labels)\n",
    "            \n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "        if (i + 1) % 200 == 0:\n",
    "            print(f\"[Epoch {epoch+1}/{num_epochs}] [Batch {i+1}/{len(dataloader)}] \"\n",
    "                  f\"[D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]\")\n",
    "\n",
    "    \n",
    "    if epoch > 50:  \n",
    "        scheduler_G.step()\n",
    "        scheduler_D.step()\n",
    "\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        generator.eval()\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(25, latent_dim, 1, 1).to(device)\n",
    "            samples = generator(z).cpu()\n",
    "            samples = 0.5 * samples + 0.5\n",
    "            grid = torchvision.utils.make_grid(samples, nrow=5)\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            plt.imshow(grid.permute(1, 2, 0))\n",
    "            plt.title(f\"Epoch {epoch+1}\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "\n",
    "            torchvision.utils.save_image(samples, f\"epoch_{epoch+1}.png\", nrow=5, normalize=True)\n",
    "        generator.train()\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
