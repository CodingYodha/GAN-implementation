{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd64bf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddacc95",
   "metadata": {},
   "source": [
    " The Generator Network (G) üé®<br>\n",
    "The Generator takes a random noise vector (latent vector) as input and tries to transform it into something that resembles the real data (e.g., an image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "824eb45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, img_shape):\n",
    "        super(Generator, self).__init__()\n",
    "        self.img_shape = img_shape # (channels, height, width)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.LeakyReLU(0.2, inplace=True), # inplace=True modifies the input directly\n",
    "\n",
    "            nn.Linear(128, 256),\n",
    "            nn.BatchNorm1d(256), # BatchNorm after linear layer\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Linear(256, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Linear(512, int(np.prod(img_shape))), # np.prod calculates product of elements\n",
    "            nn.Tanh() # To output values between -1 and 1\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        # z is the input noise vector (batch_size, latent_dim)\n",
    "        img = self.model(z)\n",
    "        # Reshape the output to the image shape\n",
    "        img = img.view(img.size(0), *self.img_shape) # * unpacks the tuple\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f4d709",
   "metadata": {},
   "source": [
    " The Discriminator Network (D) üßê<br>\n",
    "The Discriminator takes an image (either real or generated by G) as input and outputs a probability that the image is real. It's essentially a binary classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2636b1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_shape):\n",
    "        super(Discriminator ,self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)) , 512),\n",
    "            nn.LeakyReLU(0.2 , inplace=True),\n",
    "\n",
    "            nn.Linear(512 , 256),\n",
    "            nn.LeakyReLU(0.2 , inplace=True),\n",
    "\n",
    "            nn.Linear(256 , 1),\n",
    "            nn.Sigmoid() #probabilistic output (0 fake , real 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        # img is the input image (batch_size, channels, height, width)\n",
    "        img_flat = img.view(img.size(0) , -1) #flattening the image\n",
    "        validity = self.model(img_flat)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca70885",
   "metadata": {},
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "748b1856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a Discriminator with a Sigmoid output layer\n",
    "adversarial_loss = nn.BCELoss()\n",
    "\n",
    "# If your Discriminator outputs logits (no Sigmoid at the end)\n",
    "# adversarial_loss = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34822b74",
   "metadata": {},
   "source": [
    "optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "193d7b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparaneters \n",
    "lr = 0.0002\n",
    "b1 = 0.5 #adam optimizer for beta1\n",
    "b2 = 0.999 #adam optimizer for beta2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "589fc860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Generator and Discriminator\n",
    "# latent_dim, channels, img_size would be defined based on your dataset\n",
    "# e.g., for MNIST: latent_dim=100, channels=1, img_size=28\n",
    "# img_shape = (channels, img_size, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ffb641b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example configuration\n",
    "latent_dim = 100\n",
    "channels = 1      # For grayscale images like MNIST\n",
    "img_size = 28\n",
    "img_shape = (channels, img_size, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b12ae7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#initialize generator\n",
    "generator = Generator(latent_dim, img_shape).to(device)\n",
    "discriminator = Discriminator(img_shape).to(device)\n",
    "\n",
    "#optimizers\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas = (b1, b2))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr = lr, betas = (b1, b2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfc82e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ToTensor(), #converting PIL img or numpy.ndarray to tensor\n",
    "    transforms.Normalize([0.5], [0.5]) #normalizes to [-1 , 1] for a single channel\n",
    "     # For 3-channel images (e.g. CIFAR10): transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "\n",
    "\n",
    "])\n",
    "\n",
    "batch_size = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6b4dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST example\n",
    "dataset = datasets.MNIST(root=\"./data/mnist\", train=True, download=True, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943f46ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (real_imgs, _) in enumerate(dataloader): # _ are labels, not needed for basic gan\n",
    "\n",
    "        #moving the data to configured device (cpu or gpu)\n",
    "        real_imgs = real_imgs.to(device)\n",
    "\n",
    "        #adversial ground truths\n",
    "        real_labels = torch.ones(real_imgs.size(0) , 1).to(device) \n",
    "        fake_labels = torch.zeros(real_imgs.size(0) , 1).to(device)\n",
    "\n",
    "        #training the discriminator\n",
    "        optimizer_D.zero_grad() #clearing the old gradients\n",
    "\n",
    "        #loss for real imgaes\n",
    "        real_outputs = discriminator(real_imgs)\n",
    "        d_loss_real = adversarial_loss(real_outputs , real_labels)\n",
    "\n",
    "        #generate fake images\n",
    "        z = torch.randn(real_imgs.size(0) , latent_dim).to(device)\n",
    "        fake_imgs = generator(z)\n",
    "\n",
    "        #loss for fake images\n",
    "        #detaching the fake_imgs to prevent gradients from flowing back to G during D training\n",
    "        fake_outputs = discriminator(fake_imgs.detach())\n",
    "        d_loss_fake = adversarial_loss(fake_outputs, fake_labels)\n",
    "\n",
    "\n",
    "        #total discriminator loss\n",
    "        d_loss = (d_loss_real + d_loss_fake) / 2\n",
    "        d_loss.backward() #compute gradients\n",
    "        optimizer_D.step()\n",
    "\n",
    "\n",
    "        #training generator\n",
    "        optimizer_G.zero_grad() #clear old gradients\n",
    "\n",
    "\n",
    "                # We want the discriminator to think the fake images are real\n",
    "        # So we use real_labels (all 1s) as the target for the generator's output\n",
    "        # No need to generate new fake_imgs, can reuse from D training if not detached,\n",
    "        # but common practice is to generate fresh ones or re-evaluate D on them.\n",
    "        # For simplicity and clarity, let's re-evaluate.\n",
    "\n",
    "\n",
    "\n",
    "        fake_outputs_for_G = discriminator(fake_imgs)\n",
    "        g_loss = adversarial_loss(fake_outputs_for_G, real_labels) \n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step() #upgrade G's weights\n",
    "\n",
    "\n",
    "        # ---------------------\n",
    "        #  Log Progress & Save Images\n",
    "        # ---------------------\n",
    "        if (i + 1) % 200 == 0: # Log every 200 batches\n",
    "            print(\n",
    "                f\"[Epoch {epoch+1}/{num_epochs}] [Batch {i+1}/{len(dataloader)}] \"\n",
    "                f\"[D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]\"\n",
    "            )\n",
    "\n",
    "    # At the end of each epoch (or every few epochs), save some generated images\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        with torch.no_grad(): # No need to track gradients here\n",
    "            # Generate a fixed set of noise vectors to see G's progress over time\n",
    "            fixed_noise = torch.randn(25, latent_dim).to(device) # Generate 25 images\n",
    "            generated_images = generator(fixed_noise).cpu() # Move to CPU for visualization\n",
    "\n",
    "            # Rescale images from [-1, 1] to [0, 1] for display/saving\n",
    "            generated_images = 0.5 * generated_images + 0.5\n",
    "\n",
    "            grid = torchvision.utils.make_grid(generated_images, nrow=5, normalize=False)\n",
    "            plt.figure(figsize=(8,8))\n",
    "            plt.imshow(grid.permute(1, 2, 0))\n",
    "            plt.title(f'Epoch {epoch+1}')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            # You can also save the image grid:\n",
    "            # torchvision.utils.save_image(generated_images, f\"gan_images/epoch_{epoch+1}.png\", nrow=5, normalize=True)\n",
    "            # Make sure the directory \"gan_images\" exists or create it.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
